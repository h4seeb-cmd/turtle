---
description: My thoughts on the Big Idea 5.3 talk.
title: Big Idea 5.3!
toc: true
comments: true
categories: [Week 21]
layout: post
---

# Task 1

Overall, I believe that a lot of bias is unintentional, and many people can take it the wrong way. For example, people made a huge deal about Siri's voice being a woman, as they thought Apple was trying to say that women are only good at supporting men. However, this point is completely moot as there are options to change Siri's voice. Additionally, if Siri's voice was a man, these same people would say that they made the voice a man as if to say that men should be the ones doing all the important jobs. As for algorithm bias, I believe that companies check their user statistics, and they purposely target users with things like reccomendations and advertisements based on the data that they were provided.


# Task 2

I believe that this bias was not intentional on HP's part. This is because cameras are not as good at detecting and focusing on faces of color anyway. Due to the darker skin tone, some low-budget cameras, like the one installed in the laptop, don't detect exposure as well. This causes the facial tracking system to not work as well on people with darker skin. This problem could have been easily avoided if they gave the facial tracking systemm more skin tones to test with, and with further testing, this problem could be solved.

# How I Will Avoid Bias In My Code

As for how I will avoid bias in my code, I plan to do lots of testing and tuning before Night At The Museum, as not only will this help me debug my project, but it will also help avoid any sort of unintentional bias.